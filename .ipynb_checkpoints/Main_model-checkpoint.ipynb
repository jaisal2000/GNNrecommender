{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d593df68-311e-479a-975d-14a49c46878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.utils import degree, structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36d5bf0-cbf0-4c63-bf20-295691c35892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "Number of unique movies: 9724\n",
      "Number of unique users: 610\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "import os\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "'''\n",
    "# Define dataset URL and file paths\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "dataset_path = \"ml-latest-small.zip\"\n",
    "extract_path = \".\"\n",
    "\n",
    "# Download and extract dataset\n",
    "if not os.path.exists(dataset_path):\n",
    "    download_url(url, extract_path)\n",
    "extract_zip(dataset_path, extract_path)\n",
    "'''\n",
    "# Define file paths\n",
    "movie_path = \"./ml-latest-small/movies.csv\"\n",
    "rating_path = \"./ml-latest-small/ratings.csv\"\n",
    "user_path = \"./ml-latest-small/users.csv\"\n",
    "\n",
    "# Load dataset\n",
    "import pandas as pd\n",
    "\n",
    "rating_df = pd.read_csv(rating_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(rating_df.head())\n",
    "\n",
    "# Display unique movie and user counts\n",
    "print(f\"Number of unique movies: {len(rating_df['movieId'].unique())}\")\n",
    "print(f\"Number of unique users: {len(rating_df['userId'].unique())}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f52191-e7c5-4e5d-a492-2be59620a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "rating_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc2945a-e16c-41db-ab79-773a6526f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
    "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940bef4d-055c-4566-9aa6-43defbc1df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "9723\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.userId.max())\n",
    "print(rating_df.movieId.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7e4f5a-91f6-44ec-a172-d2d18de1d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "4.0    26818\n",
       "3.0    20047\n",
       "5.0    13211\n",
       "3.5    13136\n",
       "4.5     8551\n",
       "2.0     7551\n",
       "2.5     5550\n",
       "1.0     2811\n",
       "1.5     1791\n",
       "0.5     1370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8d079c-3232-48a1-a68a-5bdaed9cf7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_edge_csv(df, src_index_col, dst_index_col, link_index_col, rating_threshold=3):\n",
    "    \"\"\"\n",
    "    Loads a CSV containing edges between users and items.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing user-item interactions.\n",
    "        src_index_col (str): Column name for users.\n",
    "        dst_index_col (str): Column name for items (movies).\n",
    "        link_index_col (str): Column name for user-item interaction (ratings).\n",
    "        rating_threshold (int, optional): Threshold to determine positive edges. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list: Edge index (2xN matrix) containing the node IDs of N user-item edges.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Constructing COO format edge_index from input rating events...\")\n",
    "\n",
    "    # Get user IDs from rating events in order of occurrence\n",
    "    src = df[src_index_col].tolist()\n",
    "    \n",
    "    # Get movie IDs from rating events in order of occurrence\n",
    "    dst = df[dst_index_col].tolist()\n",
    "\n",
    "    # Apply rating threshold to filter interactions\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long)\n",
    "    \n",
    "    edge_index = [[], []]  # COO format edge index (two lists for source and destination nodes)\n",
    "\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i] >= rating_threshold:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "\n",
    "    return edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de89d585-8952-4e79-a7c6-385dc347b8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing COO format edge_index from input rating events...\n",
      "2 x 48580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "edge_index= load_edge_csv(\n",
    "rating_df,\n",
    "src_index_col='userId', dst_index_col='movieId', link_index_col=\"rating\", rating_threshold=3.5,\n",
    ")\n",
    "print(f\"{len(edge_index)} x {len(edge_index[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565f1ab8-38a3-4e44-b169-194667c6a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9443, 9444, 9445]])\n",
      "torch.Size([2, 48580])\n"
     ]
    }
   ],
   "source": [
    "#Convert to Tensor\n",
    "edge_index = torch.LongTensor(edge_index)\n",
    "print(edge_index)\n",
    "print(edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1640119e-ac2b-4189-be40-1f68d1bf3deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique users: 610\n",
      "Total unique movies: 9724\n"
     ]
    }
   ],
   "source": [
    "# Get total number of unique users and movies (before applying rating threshold)\n",
    "num_users = rating_df['userId'].nunique()  # More efficient than len(unique())\n",
    "num_movies = rating_df['movieId'].nunique()\n",
    "\n",
    "print(f\"Total unique users: {num_users}\")\n",
    "print(f\"Total unique movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f92998-34c4-40d4-9323-eb1fd655b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistics:\n",
      "- Total users: 610\n",
      "- Total movies: 9724\n",
      "- Total interactions: 48580\n",
      "- Training interactions: 38864\n",
      "- Validation interactions: 4858\n",
      "- Test interactions: 4858\n",
      "- Total nodes (users + movies): 10334\n",
      "- Unique users in training: 609\n",
      "- Unique movies in training: 5676\n"
     ]
    }
   ],
   "source": [
    "# Calculate total interactions\n",
    "num_interactions = edge_index.size(1)  # More precise than shape[1] for PyTorch tensors\n",
    "\n",
    "# Split the edges using 80/10/10 train/validation/test split\n",
    "all_indices = torch.arange(num_interactions)  # More efficient than list comprehension\n",
    "\n",
    "# First split: 80% train, 20% temp\n",
    "train_indices, temp_indices = train_test_split(\n",
    "    all_indices,\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Second split: 10% val, 10% test (50% of remaining 20%)\n",
    "val_indices, test_indices = train_test_split(\n",
    "    temp_indices,\n",
    "    test_size=0.5,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Create edge splits\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Dataset statistics:\")\n",
    "print(f\"- Total users: {num_users}\")\n",
    "print(f\"- Total movies: {num_movies}\")\n",
    "print(f\"- Total interactions: {num_interactions}\")\n",
    "print(f\"- Training interactions: {train_edge_index.size(1)}\")\n",
    "print(f\"- Validation interactions: {val_edge_index.size(1)}\")\n",
    "print(f\"- Test interactions: {test_edge_index.size(1)}\")\n",
    "print(f\"- Total nodes (users + movies): {num_users + num_movies}\")\n",
    "print(f\"- Unique users in training: {torch.unique(train_edge_index[0]).size(0)}\")\n",
    "print(f\"- Unique movies in training: {torch.unique(train_edge_index[1]).size(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "081f048d-9004-45a7-af6b-3100b03bbdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
    "    R = torch.zeros(num_users, num_movies)\n",
    "    for i in range(input_edge_index.size(1)):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "\n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros(num_users + num_movies, num_users + num_movies)\n",
    "    adj_mat[:num_users, num_users:] = R.clone()\n",
    "    adj_mat[num_users:, :num_users] = R_transpose.clone()\n",
    "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
    "    adj_mat_coo = adj_mat_coo.indices()\n",
    "    return adj_mat_coo\n",
    "\n",
    "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
    "    sparse_input_edge_index = SparseTensor(\n",
    "        row=input_edge_index[0],\n",
    "        col=input_edge_index[1],\n",
    "        sparse_sizes=(num_users + num_movies, num_users + num_movies)\n",
    "    )\n",
    "    adj_mat = sparse_input_edge_index.to_dense()\n",
    "    interact_mat = adj_mat[:num_users, num_users:]\n",
    "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
    "    return r_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e4d0f9-4392-4b9a-a8b0-664867435f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train edge index: tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n",
      "        [  610,   612,   653,  ...,   183,   183,   330]])\n",
      "Train edge index size: torch.Size([2, 77728])\n",
      "Validation edge index: tensor([[    0,     0,     0,  ..., 10226, 10236, 10240],\n",
      "        [  615,   794,  2010,  ...,   317,   204,   413]])\n",
      "Validation edge index size: torch.Size([2, 9716])\n",
      "Test edge index: tensor([[    0,     0,     0,  ..., 10301, 10302, 10329],\n",
      "        [  811,  1086,  1095,  ...,   585,   585,   183]])\n",
      "Test edge index size: torch.Size([2, 9716])\n"
     ]
    }
   ],
   "source": [
    "# convert from r_mat (interaction matrix) edge index to adjacency matrix's edge index\n",
    "# so we can feed it to model\n",
    "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
    "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
    "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)\n",
    "\n",
    "print(\"Train edge index:\", train_edge_index)\n",
    "print(\"Train edge index size:\", train_edge_index.size())\n",
    "print(\"Validation edge index:\", val_edge_index)\n",
    "print(\"Validation edge index size:\", val_edge_index.size())\n",
    "print(\"Test edge index:\", test_edge_index)\n",
    "print(\"Test edge index size:\", test_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109d7518-0879-4755-84b4-ea183df41d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for training and computing BPR loss\n",
    "# Since this is self-supervised learning, we're relying on the graph structure itself\n",
    "# We don't have labels other than the graph structure, so we need this function\n",
    "# which randomly samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a mini-batch given an adjacency matrix\n",
    "    \n",
    "    Args:\n",
    "        batch_size (int): mini-batch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "        \n",
    "    Returns:\n",
    "        tuple: user_indices, positive_item_indices, negative_item_indices\n",
    "    \"\"\"\n",
    "    # structured_negative_sampling is a PyG library\n",
    "    # Samples a negative edge (i,k) for every positive edge (i,j) in the graph\n",
    "    # and returns it as a tuple of the form (i,j,k)\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    \n",
    "    # Stack the edges into 3 x edge_index_len tensor\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    \n",
    "    # Randomly sample batch_size indices with replacement\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges.shape[1])], \n",
    "        k=batch_size\n",
    "    )\n",
    "    \n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    \n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc350c8-0558-476a-92fa-56575804b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 64.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # Define user and item embedding for direct look up\n",
    "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim)  # e_u^0\n",
    "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim)  # e_i^0\n",
    "\n",
    "        # Initialize embeddings as recommended in LightGCN paper\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple: (e_u_k, e_u_0, e_i_k, e_i_0) where:\n",
    "                - e_u_k: final user embeddings after K layers\n",
    "                - e_u_0: initial user embeddings\n",
    "                - e_i_k: final item embeddings after K layers\n",
    "                - e_i_0: initial item embeddings\n",
    "        \"\"\"\n",
    "        # Normalize adjacency matrix\n",
    "        edge_index_norm = gcn_norm(edge_index=edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        # Concatenate user and item embeddings\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight])  # E^0\n",
    "        embs = [emb_0]  # Store layer 0 embeddings\n",
    "\n",
    "        emb_k = emb_0  # Initialize embeddings for propagation\n",
    "\n",
    "        # Propagate embeddings through K layers\n",
    "        for _ in range(self.K):\n",
    "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        # Stack and average embeddings as per LightGCN paper\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1)  # E^K\n",
    "\n",
    "        # Split into user and item embeddings\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
    "\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: Tensor, norm: Tensor) -> Tensor:\n",
    "        \"\"\"Message passing operation\n",
    "        \n",
    "        Args:\n",
    "            x_j (Tensor): Embeddings of neighboring nodes (shape: [edge_index_len, embedding_dim])\n",
    "            norm (Tensor): Normalization values (shape: [edge_index_len])\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Normalized messages to be propagated\n",
    "        \"\"\"\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "layers = 3\n",
    "model = LightGCN(\n",
    "    num_users=num_users,\n",
    "    num_items=num_movies,\n",
    "    K=layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe4b550-1cab-46da-987c-97525e113b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, \n",
    "             neg_items_emb_final, neg_items_emb_0, lambda_val=1e-5):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "    \n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): Final user embeddings after K layers\n",
    "        users_emb_0 (torch.Tensor): Initial user embeddings\n",
    "        pos_items_emb_final (torch.Tensor): Final positive item embeddings after K layers\n",
    "        pos_items_emb_0 (torch.Tensor): Initial positive item embeddings\n",
    "        neg_items_emb_final (torch.Tensor): Final negative item embeddings after K layers\n",
    "        neg_items_emb_0 (torch.Tensor): Initial negative item embeddings\n",
    "        lambda_val (float, optional): Regularization coefficient. Defaults to 1e-5.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Scalar BPR loss value\n",
    "    \"\"\"\n",
    "    # Calculate regularization loss\n",
    "    reg_loss = lambda_val * (\n",
    "        users_emb_0.norm(2).pow(2) + \n",
    "        pos_items_emb_0.norm(2).pow(2) + \n",
    "        neg_items_emb_0.norm(2).pow(2)\n",
    "    )\n",
    "    \n",
    "    # Calculate positive and negative scores\n",
    "    pos_scores = torch.sum(users_emb_final * pos_items_emb_final, dim=-1)\n",
    "    neg_scores = torch.sum(users_emb_final * neg_items_emb_final, dim=-1)\n",
    "    \n",
    "    # Calculate BPR loss\n",
    "    bpr_loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores - neg_scores))\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = bpr_loss + reg_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f008767-78ce-4def-9926-b775d2b27d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generate dictionary of positive items for each user\n",
    "    \n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "        \n",
    "    Returns:\n",
    "        dict: {user_id: list of positive item_ids}\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    \n",
    "    for i in range(edge_index.size(1)):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        \n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []  # Fixed: using square brackets\n",
    "            \n",
    "        user_pos_items[user].append(item)\n",
    "    \n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "531acff9-af0c-4d92-a88d-fd6b4901f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecallPrecision_ATM(groundTruth, r, k):\n",
    "    \"\"\"Computes recall@k and precision@k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list[list[int]]): List of lists containing ground truth item_ids for each user.\n",
    "                                      Each sublist contains the true relevant items for that user.\n",
    "        r (list[list[bool]]): List of lists indicating whether each top-k recommended item\n",
    "                             is a ground truth item (true relevant) or not.\n",
    "        k (int): The number of top items to consider for evaluation metrics.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (recall@k, precision@k)\n",
    "    \"\"\"\n",
    "    # Convert to tensors if they aren't already\n",
    "    if not isinstance(r, torch.Tensor):\n",
    "        r = torch.tensor(r, dtype=torch.float)\n",
    "    if not isinstance(groundTruth, torch.Tensor):\n",
    "        user_num_liked = torch.tensor([len(gt) for gt in groundTruth], dtype=torch.float)\n",
    "    else:\n",
    "        user_num_liked = torch.tensor([len(groundTruth[i]) for i in range(len(groundTruth))], dtype=torch.float)\n",
    "\n",
    "    # Number of correctly predicted items per user\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # Fixed dim=-1 instead of dim-1\n",
    "\n",
    "    # Handle case where user has no liked items to avoid division by zero\n",
    "    user_num_liked[user_num_liked == 0] = 1e-9\n",
    "\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred / k)\n",
    "\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd63b84-4cbf-4ebe-a700-05899825ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, input_edge_index, input_exclude_edge_indices, k):\n",
    "    \"\"\"Computes evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LightGCN): trained LightGCN model\n",
    "        input_edge_index (torch.Tensor): 2 by N edge index (adjacency matrix based) for split to evaluate\n",
    "        input_exclude_edge_indices (list[torch.Tensor]): list of edge indices to exclude from evaluation\n",
    "        k (int): number of top items to consider for metrics\n",
    "\n",
    "    Returns:\n",
    "        tuple: (recall@k, precision@k, ndcg@k)\n",
    "    \"\"\"\n",
    "    # Get embeddings\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "\n",
    "    # Convert edge indices to interaction matrix format\n",
    "    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "    exclude_edge_indices = [\n",
    "        convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index)\n",
    "        for exclude_edge_index in input_exclude_edge_indices\n",
    "    ]\n",
    "\n",
    "    # Generate predicted interaction matrix\n",
    "    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "    rating = r_mat_rating.clone()\n",
    "\n",
    "    # Mask out excluded items\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        \n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "        \n",
    "        # Set excluded entries to very low value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    # Get top-k items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # Get ground truth positive items for test users\n",
    "    users = edge_index[0].unique()\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # Convert test_user_pos_items dictionary into list of lists\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # Create relevance matrix\n",
    "    r = []\n",
    "    for i, user in enumerate(users):\n",
    "        user = user.item()\n",
    "        user_true_relevant_items = test_user_pos_items.get(user, [])\n",
    "        # Create boolean list indicating whether top-k items are relevant\n",
    "        relevant_items = [item.item() in user_true_relevant_items for item in top_K_items[i]]\n",
    "        r.append(relevant_items)\n",
    "\n",
    "    r = torch.tensor(r, dtype=torch.float32)\n",
    "\n",
    "    # Compute metrics\n",
    "    recall, precision = RecallPrecision_ATM(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d1b45b-ab46-42ad-9ce0-cefb29f4def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LightGCN): LightGCN model\n",
    "        edge_index (torch.Tensor): 2 by N edge index (adjacency matrix based) for split to evaluate\n",
    "        exclude_edge_indices (list[torch.Tensor]): list of edge indices to exclude from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): lambda value for BPR loss regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (bpr_loss, recall@k, precision@k, ndcg@k)\n",
    "    \"\"\"\n",
    "    # Get embeddings through forward pass\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model(edge_index)\n",
    "\n",
    "    # Convert to interaction matrix format for negative sampling\n",
    "    r_mat_edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index)\n",
    "\n",
    "    # Generate negative samples\n",
    "    edges = structured_negative_sampling(\n",
    "        r_mat_edge_index,\n",
    "        contains_neg_self_loops=False\n",
    "    )\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges\n",
    "\n",
    "    # Get embeddings for sampled triplets\n",
    "    users_emb_final = users_emb_final[user_indices]\n",
    "    users_emb_0 = users_emb_0[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    pos_items_emb_0 = items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "    neg_items_emb_0 = items_emb_0[neg_item_indices]\n",
    "\n",
    "    # Calculate BPR loss\n",
    "    loss = bpr_loss(\n",
    "        users_emb_final,\n",
    "        users_emb_0,\n",
    "        pos_items_emb_final,\n",
    "        pos_items_emb_0,\n",
    "        neg_items_emb_final,\n",
    "        neg_items_emb_0,\n",
    "        lambda_val\n",
    "    ).item()\n",
    "\n",
    "    # Calculate metrics\n",
    "    recall, precision, ndcg = get_metrics(model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d33dc-d015-4442-9e28-e1e583027ba2",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd6e87e8-5dea-495c-8773-c4abf2335251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 1000\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITEMS_PER_EVAL = 200\n",
    "ITEMS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "600d3ce1-c110-45ac-8b73-14d068cd33dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup device and model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "model.train()  # Set model to training mode\n",
    "\n",
    "# Initialize optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "# Move data tensors to device\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device) if 'test_edge_index' in locals() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bcf7b4d-17ef-42a2-94df-96bbe88abe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs_for_bpr(model, input_edge_index):\n",
    "    \"\"\"Prepares embeddings for BPR loss calculation\n",
    "    \n",
    "    Args:\n",
    "        model (LightGCN): trained LightGCN model\n",
    "        input_edge_index (torch.Tensor): adjacency matrix based edge index\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (users_emb_final, users_emb_0, \n",
    "                pos_items_emb_final, pos_items_emb_0,\n",
    "                neg_items_emb_final, neg_items_emb_0)\n",
    "    \"\"\"\n",
    "    # Get all embeddings from model\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model(input_edge_index)\n",
    "    \n",
    "    # Convert to interaction matrix format\n",
    "    edge_index_to_use = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "    \n",
    "    # Sample mini-batch for BPR loss\n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, edge_index_to_use)\n",
    "    \n",
    "    # Move indices to correct device\n",
    "    user_indices = user_indices.to(device)\n",
    "    pos_item_indices = pos_item_indices.to(device)\n",
    "    neg_item_indices = neg_item_indices.to(device)\n",
    "    \n",
    "    # Get embeddings for sampled triplets\n",
    "    users_emb_final = users_emb_final[user_indices]  # Fixed: using [] for indexing\n",
    "    users_emb_0 = users_emb_0[user_indices]\n",
    "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
    "    pos_items_emb_0 = items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
    "    neg_items_emb_0 = items_emb_0[neg_item_indices]\n",
    "    \n",
    "    return (users_emb_final, users_emb_0, \n",
    "            pos_items_emb_final, pos_items_emb_0,\n",
    "            neg_items_emb_final, neg_items_emb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b8882-4fdc-4ee7-a10c-f3a24cb39af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training trackers\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_recall_at_ks = []\n",
    "\n",
    "for iter in tqdm(range(ITERATIONS), desc=\"Training\"):\n",
    "    # Forward propagation and get embeddings for BPR\n",
    "    users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0 = \\\n",
    "        get_embs_for_bpr(model, train_edge_index)\n",
    "\n",
    "    # Loss computation\n",
    "    train_loss = bpr_loss(\n",
    "        users_emb_final,\n",
    "        users_emb_0,\n",
    "        pos_items_emb_final,\n",
    "        pos_items_emb_0,\n",
    "        neg_items_emb_final,\n",
    "        neg_items_emb_0,\n",
    "        LAMBDA\n",
    "    )\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store training loss\n",
    "    train_losses.append(train_loss.item())\n",
    "\n",
    "    # Validation and logging\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loss, recall, precision, ndcg = evaluation(\n",
    "                model,\n",
    "                val_edge_index,\n",
    "                [train_edge_index],  # List of edge indices to exclude\n",
    "                K,\n",
    "                LAMBDA\n",
    "            )\n",
    "            \n",
    "            val_losses.append(val_loss)\n",
    "            val_recall_at_ks.append(round(recall, 5))\n",
    "\n",
    "        print(f\"Iteration {iter}/{ITERATIONS}: \"\n",
    "              f\"train_loss: {train_loss.item():.5f}, \"\n",
    "              f\"val_loss: {val_loss:.5f}, \"\n",
    "              f\"recall@{K}: {recall:.5f}, \"\n",
    "              f\"precision@{K}: {precision:.5f}, \"\n",
    "              f\"ndcg@{K}: {ndcg:.5f}\")\n",
    "        \n",
    "        model.train()  # Set back to training mode\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
